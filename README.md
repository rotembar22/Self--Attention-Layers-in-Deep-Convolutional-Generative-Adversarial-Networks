# Self-Attention Layers in Deep Convolutional Generative Adversarial Networks

![Seer Logo](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-05-25_at_1.36.58_PM.png)

## Authors
[:godmode: Bar Rotem](https://github.com/rotembaruch)<br>
[:suspect: Levkovich Uria](https://github.com/uriaLevko)<br>


## Abstract
This article will cover an approach for image generation task called self-attention GAN. This approach used long-range dependency modeling for the image generation task. The SAGANs rely on the regular or traditional convolutional GANs. Those traditional GANs can generate high-resolution details as a function of only spatially local points in a lower-resolution feature map. By using SAGANs, additional details can be generated by focusing on the location of those features. We will demonstrate whether a self-attention mechanism can improve the quality and visibility of generated images and the FID score. We performed several experiments by using the Stanford Dogs Dataset.
